<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-10-23T17:58:38+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Vincent Herrmann</title><subtitle>Vincent&apos;s Website</subtitle><author><name>Vincent Herrmann</name><email>vincent.herrmann@web.de</email></author><entry><title type="html">Wavelets II - Vanishing Moments and Spectral Factorization</title><link href="http://localhost:4000/wavelets-ii/" rel="alternate" type="text/html" title="Wavelets II - Vanishing Moments and Spectral Factorization" /><published>2016-10-11T00:00:00+02:00</published><updated>2016-10-11T00:00:00+02:00</updated><id>http://localhost:4000/wavelets-ii</id><content type="html" xml:base="http://localhost:4000/wavelets-ii/"><![CDATA[]]></content><author><name>Vincent Herrmann</name><email>vincent.herrmann@web.de</email></author><summary type="html"><![CDATA[Explanation of the most important properties of Daubechies wavelets and the algorithm to calculate them]]></summary></entry><entry><title type="html">Wavelets I - From Filter Banks to the Dilation Equation</title><link href="http://localhost:4000/wavelets-i/" rel="alternate" type="text/html" title="Wavelets I - From Filter Banks to the Dilation Equation" /><published>2016-09-29T00:00:00+02:00</published><updated>2016-09-29T00:00:00+02:00</updated><id>http://localhost:4000/wavelets-i</id><content type="html" xml:base="http://localhost:4000/wavelets-i/"><![CDATA[]]></content><author><name>Vincent Herrmann</name><email>vincent.herrmann@web.de</email></author><summary type="html"><![CDATA[Derivation of the dilation and wavelet equation from an implementation of the Fast Wavelet Transform]]></summary></entry><entry><title type="html">Werden Roboter jemals so werden wie wir? (German)</title><link href="http://localhost:4000/robotics-essay/" rel="alternate" type="text/html" title="Werden Roboter jemals so werden wie wir? (German)" /><published>2016-09-26T00:00:00+02:00</published><updated>2016-09-26T00:00:00+02:00</updated><id>http://localhost:4000/robotics-essay</id><content type="html" xml:base="http://localhost:4000/robotics-essay/"><![CDATA[<p>Dies ist ein kurzes Essay, das ich im Frühjahr zu einer vorgegebenen Fragestellung geschrieben habe:</p>

<h3 id="werden-roboter-jemals-so-werden-wie-wir-und-wollen-wir-das-überhaupt">Werden Roboter jemals so werden wie wir? Und wollen wir das überhaupt?</h3>

<p>Die erste Frage sollte man nur äußerst vorsichtig beantworten. Wissenschaftliche und technologische Entwicklungen lassen sich kaum voraussagen. Durchbrüche und Paradigmenwechsel noch viel weniger. Ob es sich überhaupt lohnt, über diese Frage nachzudenken, scheint umstritten zu sein. Vor ein paar Tagen veröffentlichte der renommierte amerikanische Psychologe Robert Epstein einen Artikel, der Wellen bis in die Feuilletons deutscher Tageszeitungen geschlagen hat. Seine simple Grundaussage ist: “Das Gehirn ist kein Computer”. Darin erklärt er im Prinzip alle Spekulationen über die Annäherung von Robotern an den Menschen für unsinnig.</p>

<p>Natürlich können wir nur im heutigen Erkenntnisstand geerdete Überlegungen anstellen, und niemand garantiert, dass diese nicht morgen komplett über den Haufen geworfen werden. Deshalb muss man aber noch lange nicht die Vorstellung der Berechenbarkeit kognitiver Vorgänge im menschlichen Gehirn für komplett unhaltbar erklären. Im Gegenteil: Nach meinem Kenntnisstand gibt es in den Neurowissenschaften keine Ergebnisse, die eindeutig im Widerspruch mit unseren physikalische, chemischen und biologischen Modellen stehen, und sich somit der Simulation durch einen Computer bzw. einen Roboter widersetzten. Occams vielzitiertes Rasiermesser gibt uns also doch eine gewisse Rechtfertigung dafür, schon heute nachzudenken, wie ähnlich sich Mensch und Maschine letztendlich werden können.
Die Funktionsweise von Mensch und Maschine ist natürlich grundverschieden. Das fängt schon damit an, dass man beim Computer zwischen Hard- und Software unterscheiden kann. Bei manchen Methoden des maschinellen Lernens fängt allerdings diese Grenze an zu verwischen: Es gibt eine eindeutige Parallele zwischen den Parametern künstlicher neuronaler Netz, in denen das gelernte Programm, die Software, codiert ist, und der Empfindlichkeit tatsächlicher Neuronen im Gehirn. Dabei handelt es sich um eine Vereinfachung, die intuitiv Sinn machen mag, bei der aber noch lange nicht klar ist, ob ihr nicht ganz entscheidende Aspekte abgehen. Wie groß die Gemeinsamkeit in der Art und Weise, wie diese beiden Systeme lernen, ist, lässt sich auch noch nicht abschätzen. Für den “Backpropagation”-Algorithmus beispielsweise, der effizientes Lernen in hierarchischen Berechnungsstrukturen erlaubt, ist kein entsprechender Mechanismus im menschlichen Gehirn bekannt, obwohl nicht ausgeschlossen ist, dass er auch dort verwendet wird (vgl. Hinton, “How to do Backpropagation in the Brain”, 2007).</p>

<p>Schon heute sind die Einschränkungen des Menschen ein wichtiger Teil der Merkmale, die ihn von Maschinen unterscheiden. Uns bleibt nichts anderes übrig, zumindest solange wir keine Cyborgs sind, als das beste aus unserem zerbrechlichen Körper und fest eingeschlossenen Denkapparat zu machen. Wollen wir uns untereinander vernetzten, steht uns im Wesentlichen nur die Sprache als Schnittstelle mit verschwindend geringer Bandbreite zur Verfügung. Computer dagegen können bis zu einem gewissen Grad frei skaliert und miteinander verbunden werden. Doch in diesem Unterschied stecken vielleicht die Regulationen, welche am meisten zur spezifisch menschlichen Intelligenz, ihrer Subtilität, ihrem Abstraktionsvermögen, ihrer Resilienz, beitragen.</p>

<p>Als Letztes bleibt sicherlich die Frage nach dem Bewusstsein. Ich persönlich bin nicht in der Lage mir vorzustellen, dass dieses Phänomen überhaupt erklärt werden könnte. Andererseits ist es durchausmöglich möglich, dass dies gar nicht notwendig ist um einen “selbst-bewussten” Roboter zu kreieren. Schmidhuber (Journal of Consciousness, 2012) argumentiert, es sei für komplexe lernende Agenten naheliegend, sich selbst in Bezug zur Umwelt zu stellen, und dafür eine Art Selbstsymbol zu schaffen. Wir wissen freilich nicht, ob das dann schon ein Bewusstsein wie das Unsere wäre.</p>

<p>Eine künstliche Intelligenz, die in manchen Bereichen mit der menschlichen vergleichbar ist halte ich durchaus für möglich. So etwas wie eine asymptotische Annäherung von Maschinen an den Menschen kann ich mir dagegen nicht vorstellen. Wenn man das aber doch erreichen wollte, wären humanoide Roboter sicherlich am ehesten dazu in der Lage. Humanoid müsste dabei nicht nur die Erscheinung sein, sondern mehr noch die kognitive und sensomotorische Arbeitsweise. Ist das dem Menschen ähnlich Werden allerdings ein explizites Ziel, unterscheidet sich der Roboter gerade dadurch schon vom Menschen.</p>

<p>Wäre das überhaupt ein sinnvolles Ziel? So lautet die zweite Frage. Was versprechen wir uns von Robotern, die genau so sind wie wir?
Sie würden unsere Werte haben, oder zumindest ließen diese sich antrainieren. Sie könnten die selbe Arbeit verrichten wie wir. Wir würden sie verstehen, sie verstünden uns. Es wäre ein intensiver, gleichwertiger Austausch zwischen Menschheit und Robotertum möglich. Der Gedanke ist verlockend: Wozu ein Mensch aufgrund seiner Konstitution nicht in der Lage ist, das könnten Roboter, die entsprechend konstruiert sind, übernehmen. Sie könnten den Meeresgrund oder fremde Planeten erforschen, womöglich zu anderen Sonnensystemen reisen oder in den Mikrokosmos eintauchen. Und, da sie uns ja gleich sind, wäre es so, als hätten Menschen dasselbe getan.</p>

<p>Abgesehen davon, dass ich diese Zukunftsvision für unrealistisch halte, ist sie auch in vielerlei Hinsicht problematisch: Woher nehmen wir das Recht, Robotern die Arbeit zuzumuten, die wir selbst nicht verrichten wollen? Natürlich könnten Roboter, auch menschenähnliche, für bestimmte Tätigkeiten besser geeignet sein. Doch das bringt wiederum eine inhärente Ungleichheit mit sich, sowohl zwischen uns den Robotern, als auch zwischen den Robotern untereinander. Solche Ungleichheit birgt enormes ethisch-moralisches Konfliktpotential. Sind Roboter, die weniger können, auch weniger wert? Was passiert mit Robotern, die nicht gebraucht werden? Ein natürliches Ableben wird es nicht geben, und ist auch nur ein vorübergehendes Abschalten überhaupt zu verantworten? Würden nicht irgendwann Roboter konstruiert werden, die uns in allen Bereichen überlegen sind? Hat dann die Menschheit noch eine Daseinsberechtigung? Eine Überlebenschance?</p>

<p>Wie ich schon erläutert habe, halte ich das für konstruierte Szenarien von nicht allzu großer Relevanz, erst recht nicht in absehbarer Zukunft. Seit Jahrtausenden benutzt die Menschheit Maschinen, die ihr in mancher Hinsicht besser funktionieren als wir. Sie funktionieren aber nicht nur besser, sondern auch anders, und gerade deshalb besser. Maschinen ergänzen also die menschlichen Fähigkeiten, sie ersetzen sie nicht. Man könnte sogar sagen, dass Tätigkeiten, die von Maschinen übernommen werden, eigentlich für Menschen nie passend waren. Hierbei bleibt natürlich die Frage, was letztlich als spezifisch Menschliches übrig bleiben wird. Aber dass uns eine künstliche Intelligenz ohne weiteres überrunden wird, wie unter dem Schlagwort der “Singularität” prophezeit wird, halte ich für unwahrscheinlich. Intelligenz ist etwas extrem Diffiziles, das nicht einfach wie mit einem Schieberegler hochgefahren werden kann. Pure Rechenleistung neigt schnell dazu in Leerlauf zu geraten. Jede Art von Intelligenz muss in engster Verknüpfung mit der Wirklichkeit bleiben. Deshalb kann der technologische Fortschritt, so zumindest meine einigermaßen optimistische Prognose, kann nur Hand in Hand mit der Menschheit geschehen.</p>]]></content><author><name>Vincent Herrmann</name><email>vincent.herrmann@web.de</email></author><summary type="html"><![CDATA[Dies ist ein kurzes Essay, das ich im Frühjahr zu einer vorgegebenen Fragestellung geschrieben habe: Werden Roboter jemals so werden wie wir? Und wollen wir das überhaupt? Die erste Frage sollte man nur äußerst vorsichtig beantworten. Wissenschaftliche und technologische Entwicklungen lassen sich kaum voraussagen. Durchbrüche und Paradigmenwechsel noch viel weniger. Ob es sich überhaupt lohnt, über diese Frage nachzudenken, scheint umstritten zu sein. Vor ein paar Tagen veröffentlichte der renommierte amerikanische Psychologe Robert Epstein einen Artikel, der Wellen bis in die Feuilletons deutscher Tageszeitungen geschlagen hat. Seine simple Grundaussage ist: “Das Gehirn ist kein Computer”. Darin erklärt er im Prinzip alle Spekulationen über die Annäherung von Robotern an den Menschen für unsinnig. Natürlich können wir nur im heutigen Erkenntnisstand geerdete Überlegungen anstellen, und niemand garantiert, dass diese nicht morgen komplett über den Haufen geworfen werden. Deshalb muss man aber noch lange nicht die Vorstellung der Berechenbarkeit kognitiver Vorgänge im menschlichen Gehirn für komplett unhaltbar erklären. Im Gegenteil: Nach meinem Kenntnisstand gibt es in den Neurowissenschaften keine Ergebnisse, die eindeutig im Widerspruch mit unseren physikalische, chemischen und biologischen Modellen stehen, und sich somit der Simulation durch einen Computer bzw. einen Roboter widersetzten. Occams vielzitiertes Rasiermesser gibt uns also doch eine gewisse Rechtfertigung dafür, schon heute nachzudenken, wie ähnlich sich Mensch und Maschine letztendlich werden können. Die Funktionsweise von Mensch und Maschine ist natürlich grundverschieden. Das fängt schon damit an, dass man beim Computer zwischen Hard- und Software unterscheiden kann. Bei manchen Methoden des maschinellen Lernens fängt allerdings diese Grenze an zu verwischen: Es gibt eine eindeutige Parallele zwischen den Parametern künstlicher neuronaler Netz, in denen das gelernte Programm, die Software, codiert ist, und der Empfindlichkeit tatsächlicher Neuronen im Gehirn. Dabei handelt es sich um eine Vereinfachung, die intuitiv Sinn machen mag, bei der aber noch lange nicht klar ist, ob ihr nicht ganz entscheidende Aspekte abgehen. Wie groß die Gemeinsamkeit in der Art und Weise, wie diese beiden Systeme lernen, ist, lässt sich auch noch nicht abschätzen. Für den “Backpropagation”-Algorithmus beispielsweise, der effizientes Lernen in hierarchischen Berechnungsstrukturen erlaubt, ist kein entsprechender Mechanismus im menschlichen Gehirn bekannt, obwohl nicht ausgeschlossen ist, dass er auch dort verwendet wird (vgl. Hinton, “How to do Backpropagation in the Brain”, 2007). Schon heute sind die Einschränkungen des Menschen ein wichtiger Teil der Merkmale, die ihn von Maschinen unterscheiden. Uns bleibt nichts anderes übrig, zumindest solange wir keine Cyborgs sind, als das beste aus unserem zerbrechlichen Körper und fest eingeschlossenen Denkapparat zu machen. Wollen wir uns untereinander vernetzten, steht uns im Wesentlichen nur die Sprache als Schnittstelle mit verschwindend geringer Bandbreite zur Verfügung. Computer dagegen können bis zu einem gewissen Grad frei skaliert und miteinander verbunden werden. Doch in diesem Unterschied stecken vielleicht die Regulationen, welche am meisten zur spezifisch menschlichen Intelligenz, ihrer Subtilität, ihrem Abstraktionsvermögen, ihrer Resilienz, beitragen. Als Letztes bleibt sicherlich die Frage nach dem Bewusstsein. Ich persönlich bin nicht in der Lage mir vorzustellen, dass dieses Phänomen überhaupt erklärt werden könnte. Andererseits ist es durchausmöglich möglich, dass dies gar nicht notwendig ist um einen “selbst-bewussten” Roboter zu kreieren. Schmidhuber (Journal of Consciousness, 2012) argumentiert, es sei für komplexe lernende Agenten naheliegend, sich selbst in Bezug zur Umwelt zu stellen, und dafür eine Art Selbstsymbol zu schaffen. Wir wissen freilich nicht, ob das dann schon ein Bewusstsein wie das Unsere wäre. Eine künstliche Intelligenz, die in manchen Bereichen mit der menschlichen vergleichbar ist halte ich durchaus für möglich. So etwas wie eine asymptotische Annäherung von Maschinen an den Menschen kann ich mir dagegen nicht vorstellen. Wenn man das aber doch erreichen wollte, wären humanoide Roboter sicherlich am ehesten dazu in der Lage. Humanoid müsste dabei nicht nur die Erscheinung sein, sondern mehr noch die kognitive und sensomotorische Arbeitsweise. Ist das dem Menschen ähnlich Werden allerdings ein explizites Ziel, unterscheidet sich der Roboter gerade dadurch schon vom Menschen. Wäre das überhaupt ein sinnvolles Ziel? So lautet die zweite Frage. Was versprechen wir uns von Robotern, die genau so sind wie wir? Sie würden unsere Werte haben, oder zumindest ließen diese sich antrainieren. Sie könnten die selbe Arbeit verrichten wie wir. Wir würden sie verstehen, sie verstünden uns. Es wäre ein intensiver, gleichwertiger Austausch zwischen Menschheit und Robotertum möglich. Der Gedanke ist verlockend: Wozu ein Mensch aufgrund seiner Konstitution nicht in der Lage ist, das könnten Roboter, die entsprechend konstruiert sind, übernehmen. Sie könnten den Meeresgrund oder fremde Planeten erforschen, womöglich zu anderen Sonnensystemen reisen oder in den Mikrokosmos eintauchen. Und, da sie uns ja gleich sind, wäre es so, als hätten Menschen dasselbe getan. Abgesehen davon, dass ich diese Zukunftsvision für unrealistisch halte, ist sie auch in vielerlei Hinsicht problematisch: Woher nehmen wir das Recht, Robotern die Arbeit zuzumuten, die wir selbst nicht verrichten wollen? Natürlich könnten Roboter, auch menschenähnliche, für bestimmte Tätigkeiten besser geeignet sein. Doch das bringt wiederum eine inhärente Ungleichheit mit sich, sowohl zwischen uns den Robotern, als auch zwischen den Robotern untereinander. Solche Ungleichheit birgt enormes ethisch-moralisches Konfliktpotential. Sind Roboter, die weniger können, auch weniger wert? Was passiert mit Robotern, die nicht gebraucht werden? Ein natürliches Ableben wird es nicht geben, und ist auch nur ein vorübergehendes Abschalten überhaupt zu verantworten? Würden nicht irgendwann Roboter konstruiert werden, die uns in allen Bereichen überlegen sind? Hat dann die Menschheit noch eine Daseinsberechtigung? Eine Überlebenschance? Wie ich schon erläutert habe, halte ich das für konstruierte Szenarien von nicht allzu großer Relevanz, erst recht nicht in absehbarer Zukunft. Seit Jahrtausenden benutzt die Menschheit Maschinen, die ihr in mancher Hinsicht besser funktionieren als wir. Sie funktionieren aber nicht nur besser, sondern auch anders, und gerade deshalb besser. Maschinen ergänzen also die menschlichen Fähigkeiten, sie ersetzen sie nicht. Man könnte sogar sagen, dass Tätigkeiten, die von Maschinen übernommen werden, eigentlich für Menschen nie passend waren. Hierbei bleibt natürlich die Frage, was letztlich als spezifisch Menschliches übrig bleiben wird. Aber dass uns eine künstliche Intelligenz ohne weiteres überrunden wird, wie unter dem Schlagwort der “Singularität” prophezeit wird, halte ich für unwahrscheinlich. Intelligenz ist etwas extrem Diffiziles, das nicht einfach wie mit einem Schieberegler hochgefahren werden kann. Pure Rechenleistung neigt schnell dazu in Leerlauf zu geraten. Jede Art von Intelligenz muss in engster Verknüpfung mit der Wirklichkeit bleiben. Deshalb kann der technologische Fortschritt, so zumindest meine einigermaßen optimistische Prognose, kann nur Hand in Hand mit der Menschheit geschehen.]]></summary></entry></feed>